import ollama
import logging
from typing import List, Dict, Any
import json

logger = logging.getLogger(__name__)

class OllamaService:
    def __init__(self, model_name="llama3"):
        self.model_name = model_name
        self.client = ollama.Client(host='http://localhost:11434') 
        print("ğŸ”§ Ollama Client baÅŸlatÄ±ldÄ±. GPU kullanÄ±mÄ± kontrol ediliyor...")
        print("ğŸ’¡ CPU kullanÄ±mÄ± iÃ§in ayar denendi (Not: AsÄ±l ayar model Ã§aÄŸrÄ±sÄ±ndadÄ±r).")
        
    def analyze_patent_differences(self, user_patent: str, similar_patents: List[str]) -> Dict[str, Any]:

        prompt = f"""
        Patent Fark Analizi GÃ¶revi:
        
        KullanÄ±cÄ±nÄ±n Patent Fikri: {user_patent}  # KullanÄ±cÄ±nÄ±n girdiÄŸi patent fikri
        
        Benzer Patentler:
        {chr(10).join([f"{i+1}. {patent}" for i, patent in enumerate(similar_patents)])}  # Benzer patentleri liste ÅŸeklinde gÃ¶ster
        
        LÃ¼tfen:
        1. KullanÄ±cÄ±nÄ±n fikri ile benzer patentler arasÄ±ndaki temel farklarÄ± bul
        2. Yenilik potansiyelini deÄŸerlendir (YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k)
        3. Hangi yÃ¶nlerin gerÃ§ekten yeni olduÄŸunu belirt
        4. GeliÅŸtirme Ã¶nerileri sun
        5. Stratejik tavsiyeler ver
        
        JSON formatÄ±nda cevap ver:  # AI'dan yapÄ±landÄ±rÄ±lmÄ±ÅŸ JSON cevap istiyoruz
        {{
            "differences": ["fark1", "fark2", ...],  # FarklÄ±lÄ±klar listesi
            "novelty_score": "YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k",  # Yenilik puanÄ±
            "novel_aspects": ["yenilik1", "yenilik2", ...],  # Yeni olan yÃ¶nler
            "improvement_suggestions": ["Ã¶neri1", "Ã¶neri2", ...],  # GeliÅŸtirme Ã¶nerileri
            "strategic_advice": "stratejik tavsiye",  # Stratejik tavsiye
            "risk_assessment": "risk deÄŸerlendirmesi"  # Risk analizi
        }}
        """
        try:
            # Ollama'ya prompt'u gÃ¶nder ve cevap al
            response = self.client.generate(
                model=self.model_name,  # KullanÄ±lacak model
                prompt=prompt,  # HazÄ±rladÄ±ÄŸÄ±mÄ±z prompt
                options={
                    'temperature': 0.3,  # DÃ¼ÅŸÃ¼k temperature = daha tutarlÄ± cevaplar
                    'top_p': 0.9,  # Kelime seÃ§iminde Ã§eÅŸitlilik kontrolÃ¼
                    # YENÄ° EKLENEN SATIR: GPU kullanÄ±mÄ±nÄ± kapatmayÄ± dene
                    'num_gpu': 0
                }
            )
            
            # AI'dan gelen ham metni JSON'a dÃ¶nÃ¼ÅŸtÃ¼r
            result = self._parse_json_response(response['response'])
            return result  # Analiz sonuÃ§larÄ±nÄ± dÃ¶ndÃ¼r
            
        except Exception as e:  # Herhangi bir hata olursa
            logger.error(f"Ollama analiz hatasÄ±: {e}")  # HatayÄ± logla
            return self._get_default_response()  # VarsayÄ±lan hata mesajÄ±nÄ± dÃ¶ndÃ¼r
    
    def generate_patent_report(self, analysis_results: Dict[str, Any]) -> str:
        """AI analiz sonuÃ§larÄ±nÄ± kullanarak detaylÄ± patent raporu oluÅŸturur"""
        
        # Rapor oluÅŸturma prompt'u
        prompt = f"""
        Patent Analiz Raporu OluÅŸtur:
        
        Analiz SonuÃ§larÄ±: {json.dumps(analysis_results, ensure_ascii=False)}  # Analiz sonuÃ§larÄ±nÄ± JSON olarak ekle
        
        TÃ¼rkÃ§e olarak profesyonel bir patent analiz raporu oluÅŸtur:
        - GiriÅŸ  # Raporun giriÅŸ bÃ¶lÃ¼mÃ¼
        - Yenilik DeÄŸerlendirmesi  # Yenilik analizi
        - Fark Analizi  # FarklÄ±lÄ±klarÄ±n detaylÄ± analizi
        - Riskler ve FÄ±rsatlar  # Risk ve fÄ±rsat deÄŸerlendirmesi
        - Ã–neriler  # GeliÅŸtirme Ã¶nerileri
        - SonuÃ§  # Genel deÄŸerlendirme
        
        Rapor maksimum 500 kelime olmalÄ±.  # Uzunluk sÄ±nÄ±rlamasÄ±
        """
        
        try:
            # AI'dan rapor oluÅŸturmasÄ±nÄ± iste
            response = self.client.generate(
                model=self.model_name,  # AynÄ± modeli kullan
                prompt=prompt,  # Rapor prompt'u
                # YENÄ° EKLENEN OPTIONS BLOÄU: GPU kullanÄ±mÄ±nÄ± kapatmayÄ± dene
                options={'num_gpu': 0} 
            )
            return response['response']  # OluÅŸturulan raporu dÃ¶ndÃ¼r
        except Exception as e:  # Hata durumu
            logger.error(f"Rapor oluÅŸturma hatasÄ±: {e}")  # HatayÄ± logla
            return "Rapor oluÅŸturulamadÄ±."  # Hata mesajÄ± dÃ¶ndÃ¼r
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """AI'dan gelen ham metni temizleyip JSON'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
        try:
            # AI bazen JSON dÄ±ÅŸÄ±nda ekstra text ekleyebilir, onlarÄ± temizle
            start_idx = response.find('{')  # Ä°lk { karakterinin pozisyonunu bul
            end_idx = response.rfind('}') + 1  # Son } karakterinin pozisyonunu bul (+1 dahil etmek iÃ§in)
            if start_idx != -1 and end_idx != -1:  # EÄŸer hem { hem } bulunduysa
                json_str = response[start_idx:end_idx]  # Sadece JSON kÄ±smÄ±nÄ± al
                return json.loads(json_str)  # String'i JSON objesine dÃ¶nÃ¼ÅŸtÃ¼r
        except:  # EÄŸer JSON parse edilemezse
            pass  # Sessizce devam et ve varsayÄ±lan response'u dÃ¶ndÃ¼r
        
        return self._get_default_response()  # Parse edilemezse varsayÄ±lanÄ± dÃ¶ndÃ¼r
    
    def _get_default_response(self) -> Dict[str, Any]:
        """Sistem hatalarÄ± iÃ§in varsayÄ±lan response oluÅŸturur"""
        return {
            "differences": ["Analiz yapÄ±lamadÄ±"],  # Hata mesajÄ±
            "novelty_score": "Belirsiz",  # Belirsiz yenilik puanÄ±
            "novel_aspects": ["Analiz yapÄ±lamadÄ±"],  # Hata mesajÄ±
            "improvement_suggestions": ["Sistem hatasÄ±"],  # Hata mesajÄ±
            "strategic_advice": "Tekrar deneyin",  # KullanÄ±cÄ±ya tavsiye
            "risk_assessment": "Belirsiz"  # Belirsiz risk deÄŸerlendirmesi
        }  # KullanÄ±cÄ±nÄ±n hiÃ§ response almamasÄ±ndansa bu mesajlarÄ± almasÄ± daha iyi
